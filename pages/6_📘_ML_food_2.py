# -*- coding: utf-8 -*-
# üìò ‡∏´‡∏ô‡πâ‡∏≤‡πÇ‡∏ä‡∏ß‡πå‡πÇ‡∏Ñ‡πâ‡∏î‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå Healthy vs Junk Food (‡∏ù‡∏±‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡πÑ‡∏ß‡πâ‡∏ï‡∏£‡∏á ‡πÜ ‡πÑ‡∏°‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå)
# ‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå pages/ ‡∏Ç‡∏≠‡∏á‡πÅ‡∏≠‡∏õ Streamlit

import streamlit as st

st.set_page_config(page_title="‡πÇ‡∏ä‡∏ß‡πå‡πÇ‡∏Ñ‡πâ‡∏î Healthy vs Junk Food", page_icon="üìò", layout="wide")
st.title("üìò ‡πÇ‡∏ä‡∏ß‡πå‡πÇ‡∏Ñ‡πâ‡∏î‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå: Healthy vs Junk Food")
st.caption("4 ‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á + ‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏£‡∏±‡∏ô")

# -------------------------------------------------------------------
# 1) RULE-BASED MAPPING
# -------------------------------------------------------------------
st.header("1) ‡∏Å‡∏é‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏≤‡∏´‡∏≤‡∏£ (Rule-based Mapping)")
st.markdown(
    "- ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡πÅ‡∏õ‡∏•‡∏á **‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå/‡∏Ñ‡∏•‡∏≤‡∏™‡∏î‡∏¥‡∏ö** ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö `Healthy / Unhealthy`\n"
    "- ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î‡πÅ‡∏ö‡∏ö‡∏ó‡∏≠‡∏î/‡∏´‡∏ß‡∏≤‡∏ô/‡∏°‡∏±‡∏ô ‚Üí Unhealthy, ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î‡∏ô‡∏∂‡πà‡∏á/‡∏¢‡πà‡∏≤‡∏á/‡∏ú‡∏±‡∏Å‡πÄ‡∏¢‡∏≠‡∏∞ ‚Üí Healthy\n"
    "- ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç ‡πÉ‡∏´‡πâ **‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô = Healthy** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á false positive ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô junk"
)

code_mapping = r'''
# mapping_rules.py ‚Äî ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å
def map_class_to_label(cls_name: str) -> str:
    c = cls_name.lower().strip()

    # (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á) ‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Æ‡∏•‡∏ï‡∏µ‡πâ
    JUNK_LIST = {"fried_chicken","pizza","burger","donut","‡πÄ‡∏Ñ‡πâ‡∏Å","‡∏Ç‡πâ‡∏≤‡∏ß‡∏ú‡∏±‡∏î","‡∏ú‡∏±‡∏î‡πÑ‡∏ó‡∏¢","‡∏ö‡∏¥‡∏á‡∏ã‡∏π","‡∏ä‡∏≤‡πÄ‡∏¢‡πá‡∏ô","‡∏ä‡∏≤‡∏ô‡∏°‡πÑ‡∏Ç‡πà‡∏°‡∏∏‡∏Å"}
    # (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á) ‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏Æ‡∏•‡∏ï‡∏µ‡πâ
    HEALTHY_LIST = {"salad","caprese_salad","beet_salad","‡∏õ‡∏•‡∏≤‡∏ô‡∏∂‡πà‡∏á","‡∏õ‡∏•‡∏≤‡πÄ‡∏ú‡∏≤","‡πÑ‡∏Å‡πà‡∏¢‡πà‡∏≤‡∏á","‡∏¢‡∏≥‡∏ß‡∏∏‡πâ‡∏ô‡πÄ‡∏™‡πâ‡∏ô","‡∏ï‡πâ‡∏°‡∏¢‡∏≥","‡πÅ‡∏Å‡∏á‡∏à‡∏∑‡∏î"}

    # ‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î‡πÄ‡∏™‡∏£‡∏¥‡∏°
    JUNK_KEYWORDS = ["fried","deep_fried","fries","donut","cake","sugar","butter","‡∏ó‡∏≠‡∏î","‡∏ä‡∏∏‡∏ö‡πÅ‡∏õ‡πâ‡∏á","‡∏´‡∏ß‡∏≤‡∏ô","‡∏°‡∏±‡∏ô‡πÄ‡∏¢‡∏¥‡πâ‡∏°","‡∏ä‡∏≤‡∏ô‡∏°"]
    HEALTHY_KEYWORDS = ["salad","grilled","steamed","boiled","soup","‡∏¢‡πà‡∏≤‡∏á","‡∏ô‡∏∂‡πà‡∏á","‡∏•‡∏ß‡∏Å","‡πÅ‡∏Å‡∏á‡∏à‡∏∑‡∏î","‡∏ú‡∏±‡∏Å‡πÄ‡∏¢‡∏≠‡∏∞"]

    if c in JUNK_LIST:            return "Unhealthy"
    if c in HEALTHY_LIST:         return "Healthy"
    if any(k in c for k in JUNK_KEYWORDS):     return "Unhealthy"
    if any(k in c for k in HEALTHY_KEYWORDS):  return "Healthy"
    return "Healthy"  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
'''
st.code(code_mapping, language="python")

# -------------------------------------------------------------------
# 2) DATA PREP ‚Üí CSV
# -------------------------------------------------------------------
st.header("2) ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: ‡∏™‡πÅ‡∏Å‡∏ô‡∏£‡∏π‡∏õ ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á CSV (Train/Val)")
st.markdown(
    "- ‡∏™‡πÅ‡∏Å‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `images/‡∏Ñ‡∏•‡∏≤‡∏™/‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û` ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏°‡πá‡∏õ‡πÄ‡∏õ‡πá‡∏ô `filepath,label`\n"
    "- ‡πÅ‡∏ö‡πà‡∏á **Train/Validation** ‡πÅ‡∏ö‡∏ö stratified keeping class ratio\n"
    "- ‡πÑ‡∏î‡πâ‡πÑ‡∏ü‡∏•‡πå `data/train.csv` ‡πÅ‡∏•‡∏∞ `data/val.csv`"
)

code_prep = r'''
# prepare_dataset.py ‚Äî ‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏£‡∏π‡∏õ‡πÄ‡∏õ‡πá‡∏ô CSV
import os, csv, random
from typing import List, Tuple

def scan_images(images_dir: str) -> List[Tuple[str, str]]:
    items = []
    for cls in sorted(os.listdir(images_dir)):
        cdir = os.path.join(images_dir, cls)
        if not os.path.isdir(cdir):
            continue
        label = map_class_to_label(cls)  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏Å‡∏é‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠ (1)
        for root, _, files in os.walk(cdir):
            for f in files:
                if f.lower().endswith((".jpg",".jpeg",".png",".bmp",".webp")):
                    items.append((os.path.join(root, f), label))
    return items

def stratified_split(items, val_ratio=0.2, seed=42):
    random.seed(seed)
    by = {}
    for p,l in items:
        by.setdefault(l, []).append((p,l))
    tr, va = [], []
    for l, arr in by.items():
        random.shuffle(arr)
        n_val = max(1, int(len(arr) * val_ratio))
        va += arr[:n_val]
        tr += arr[n_val:]
    random.shuffle(tr); random.shuffle(va)
    return tr, va

def write_csv(rows, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["filepath","label"])
        w.writerows(rows)

# ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ:
# items = scan_images("./images")
# tr, va = stratified_split(items, 0.2)
# write_csv(tr, "data/train.csv"); write_csv(va, "data/val.csv")
'''
st.code(code_prep, language="python")

# -------------------------------------------------------------------
# 3) TRAINING ‚Äî ResNet-18
# -------------------------------------------------------------------
st.header("3) ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ResNet-18 (Fine-tune)")
st.markdown(
    "- ‡πÇ‡∏´‡∏•‡∏î **ResNet-18 (ImageNet weights)** ‚Üí ‡∏õ‡∏£‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô 2 ‡∏Ñ‡∏•‡∏≤‡∏™\n"
    "- ‡πÉ‡∏ä‡πâ **CrossEntropyLoss + Adam**\n"
    "- ‡πÄ‡∏ã‡∏ü `outputs/best_model.pt` ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡πà‡∏≤ **val acc** ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô"
)

code_train = r'''
# train.py ‚Äî ‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from torchvision.models import ResNet18_Weights
from PIL import Image
import pandas as pd, os

IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD  = [0.229, 0.224, 0.225]

class CsvImageDataset(Dataset):
    def __init__(self, csv_path, tfm):
        df = pd.read_csv(csv_path)
        self.paths = df["filepath"].tolist()
        labels = df["label"].tolist()
        names = sorted(list(set(labels)))
        self.name_to_idx = {n:i for i,n in enumerate(names)}
        self.idx_to_name = names
        self.labels = [self.name_to_idx[l] for l in labels]
        self.tfm = tfm
    def __len__(self): return len(self.paths)
    def __getitem__(self, i):
        img = Image.open(self.paths[i]).convert("RGB")
        return self.tfm(img), self.labels[i]

def build_loaders(csv_train, csv_val, bs=32):
    tfm_tr = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ToTensor(),
        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),
    ])
    tfm_va = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.ToTensor(),
        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),
    ])
    ds_tr = CsvImageDataset(csv_train, tfm_tr)
    ds_va = CsvImageDataset(csv_val, tfm_va)
    return (
        DataLoader(ds_tr, batch_size=bs, shuffle=True,  num_workers=2, pin_memory=True),
        DataLoader(ds_va, batch_size=bs, shuffle=False, num_workers=2, pin_memory=True),
        ds_tr.idx_to_name
    )

def train(csv_train, csv_val, epochs=8, lr=3e-4, out_dir="outputs"):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    loader_tr, loader_va, class_names = build_loaders(csv_train, csv_val, 32)

    model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)
    model.fc = nn.Sequential(
        nn.Linear(model.fc.in_features, 128),
        nn.ReLU(),
        nn.Dropout(0.2),
        nn.Linear(128, len(class_names)),
    )
    model.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    best_acc, best_path = 0.0, os.path.join(out_dir, "best_model.pt")
    os.makedirs(out_dir, exist_ok=True)

    for epoch in range(1, epochs+1):
        # train
        model.train(); tot, corr, loss_sum = 0, 0, 0.0
        for x, y in loader_tr:
            x, y = x.to(device), torch.tensor(y, dtype=torch.long, device=device)
            optimizer.zero_grad()
            out = model(x)
            loss = criterion(out, y)
            loss.backward(); optimizer.step()
            loss_sum += float(loss) * x.size(0)
            corr += (out.argmax(1)==y).sum().item()
            tot  += x.size(0)
        tr_loss, tr_acc = loss_sum/tot, corr/tot

        # validate
        model.eval(); tot, corr, loss_sum = 0, 0, 0.0
        with torch.no_grad():
            for x, y in loader_va:
                x, y = x.to(device), torch.tensor(y, dtype=torch.long, device=device)
                out = model(x); loss = criterion(out, y)
                loss_sum += float(loss) * x.size(0)
                corr += (out.argmax(1)==y).sum().item()
                tot  += x.size(0)
        va_loss, va_acc = loss_sum/tot, corr/tot

        print(f"Epoch {epoch}/{epochs} | train {tr_acc:.3f} | val {va_acc:.3f}")
        if va_acc > best_acc:
            best_acc = va_acc
            torch.save({
                "model_state_dict": model.state_dict(),
                "class_names": class_names,
                "mean": IMAGENET_MEAN,
                "std": IMAGENET_STD,
            }, best_path)
            print(f"Saved best: {best_path} (acc={best_acc:.3f})")

# ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ:
# train('data/train.csv','data/val.csv', epochs=8, lr=3e-4, out_dir='outputs')
'''
st.code(code_train, language="python")

# -------------------------------------------------------------------
# 4) INFERENCE ‚Äî ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
# -------------------------------------------------------------------
st.header("4) ‡∏ô‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Predict/Inference)")
st.markdown(
    "- ‡πÇ‡∏´‡∏•‡∏î `best_model.pt` ‚Üí ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ 224√ó224 ‚Üí softmax ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î\n"
    "- ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á CLI, batch script ‡∏´‡∏£‡∏∑‡∏≠‡∏ù‡∏±‡∏á‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ Streamlit ‡∏≠‡∏∑‡πà‡∏ô"
)

code_predict = r'''
# predict.py ‚Äî ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß
import torch
from PIL import Image
from torchvision import transforms, models

def load_model(ckpt_path, device):
    ckpt = torch.load(ckpt_path, map_location=device)
    model = models.resnet18(weights=None)
    model.fc = torch.nn.Sequential(
        torch.nn.Linear(model.fc.in_features, 128),
        torch.nn.ReLU(),
        torch.nn.Dropout(0.2),
        torch.nn.Linear(128, len(ckpt["class_names"])),
    )
    model.load_state_dict(ckpt["model_state_dict"])
    model.to(device).eval()
    return model, ckpt["class_names"], ckpt["mean"], ckpt["std"]

def predict_image(img_path, ckpt_path="outputs/best_model.pt"):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model, names, mean, std = load_model(ckpt_path, device)
    tfm = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.ToTensor(),
        transforms.Normalize(mean, std),
    ])
    img = Image.open(img_path).convert("RGB")
    x = tfm(img).unsqueeze(0).to(device)
    with torch.no_grad():
        prob = torch.softmax(model(x), dim=1)[0].cpu().numpy()
    idx = int(prob.argmax())
    return names[idx], float(prob[idx])

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
# label, p = predict_image("path/to/test.jpg", "outputs/best_model.pt")
# print(label, p)
'''
st.code(code_predict, language="python")

# -------------------------------------------------------------------
# ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á
# -------------------------------------------------------------------
st.subheader("‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á (‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡∏°‡∏¥‡∏ô‡∏±‡∏•)")
st.code("""\
# 1) ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° CSV
python prepare_dataset.py --images_dir ./images --out_dir ./data --val_ratio 0.2

# 2) ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
python train.py --csv_train data/train.csv --csv_val data/val.csv --epochs 8 --batch_size 32 --lr 3e-4 --out_dir outputs

# 3) ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
python predict.py --ckpt outputs/best_model.pt --image path/to/test.jpg
""", language="bash")

# -------------------------------------------------------------------
# ‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
# -------------------------------------------------------------------
st.header("‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏ô‡∏≥‡πÑ‡∏õ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£ / ‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á?")
st.markdown("""
- **‡πÅ‡∏≠‡∏õ‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ô‡πÄ‡∏Æ‡∏•‡∏ï‡∏µ‡πâ**: ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ Healthy/Unhealthy ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏°‡∏ô‡∏π
- **POS/CCTV ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£**: ‡∏ï‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏£‡∏±‡∏ß/‡πÅ‡∏Ñ‡∏ä‡πÄ‡∏ä‡∏µ‡∏¢‡∏£‡πå ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏±‡∏ö‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏∑‡πà‡∏°‡∏´‡∏ß‡∏≤‡∏ô/‡∏Ç‡∏≠‡∏á‡∏ó‡∏≠‡∏î‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå
- **‡πÄ‡∏°‡∏ô‡∏π‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•**: ‡∏ï‡∏¥‡∏î‡∏õ‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ‡πÉ‡∏™‡πà‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Æ‡∏•‡∏ï‡∏µ‡πâ + ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•/‡πÑ‡∏Ç‡∏°‡∏±‡∏ô
- **Recommender ‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•**: ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡πÅ‡∏Ñ‡∏•‡∏≠‡∏£‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
- **‡∏Ç‡∏¢‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô Multi-Class**: ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ä‡∏ô‡∏¥‡∏î‡∏≠‡∏≤‡∏´‡∏≤‡∏£ 10‚Äì50 ‡∏Ñ‡∏•‡∏≤‡∏™ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÅ‡∏Ñ‡∏•‡∏≠‡∏£‡∏µ‡πà‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì
- **‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠**: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ö‡∏≤ (MobileNet/Vit-Tiny, TorchScript/ONNX) ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏≠‡∏ü‡πÑ‡∏•‡∏ô‡πå
- **MLOps ‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏∞‡∏ö‡∏ö**: Pipeline ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Üí ‡πÄ‡∏ó‡∏£‡∏ô ‚Üí ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ‚Üí ‡∏î‡∏µ‡∏û‡∏•‡∏≠‡∏¢ ‚Üí ‡∏°‡∏≠‡∏ô‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå model drift
""")

st.success("‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏û‡∏£‡∏µ‡πÄ‡∏ã‡∏ô‡∏ï‡πå‡πÅ‡∏•‡πâ‡∏ß! ‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏µ‡∏•‡∏∞‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ ‡πÇ‡∏ä‡∏ß‡πå‡πÇ‡∏Ñ‡πâ‡∏î‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÅ‡∏•‡πâ‡∏ß‡∏õ‡∏¥‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î üëç")
