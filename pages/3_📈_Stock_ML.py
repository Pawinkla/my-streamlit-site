# app.py ‚Äî Stock Buy / Not Buy (Thai UI, Streamlit)
# - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì revenue_growth_ttm ‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏á‡∏ö TTM ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö TTM ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
# - ‡πÅ‡∏û‡∏ï‡∏ä‡πå‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö sklearn ‡πÉ‡∏´‡∏°‡πà (‡πÄ‡∏ï‡∏¥‡∏° monotonic_cst)
# - normalize proba ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 0..1 ‡πÄ‡∏™‡∏°‡∏≠
# - ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

import json
import warnings
from typing import List

import numpy as np
import pandas as pd
import streamlit as st
import yfinance as yf
from joblib import load
import sklearn

warnings.filterwarnings("ignore")
st.set_page_config(page_title="‡∏™‡πÅ‡∏Å‡∏ô‡∏´‡∏∏‡πâ‡∏ô: ‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠/‡πÑ‡∏°‡πà‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠ (Fundamental ML)", layout="wide")

# =============================
# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• + ‡πÅ‡∏û‡∏ï‡∏ä‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ
# =============================
def _patch_monotonic_cst(model):
    """‡πÄ‡∏ï‡∏¥‡∏° attribute 'monotonic_cst' ‡πÉ‡∏´‡πâ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô RF/ET ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• sklearn ‡πÄ‡∏Å‡πà‡∏≤
    ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö sklearn >=1.4 ‡πÑ‡∏î‡πâ"""
    try:
        est = model.steps[-1][1] if hasattr(model, "steps") else model
        if hasattr(est, "estimators_"):
            for tree in est.estimators_:
                if not hasattr(tree, "monotonic_cst"):
                    setattr(tree, "monotonic_cst", None)
    except Exception:
        pass

@st.cache_resource(show_spinner=False)
def load_model_and_meta(model_path="buy_model_pipeline.pkl",
                        meta_path="model_meta.json"):
    pipe = None
    try:
        pipe = load(model_path)
        _patch_monotonic_cst(pipe)
    except Exception as e:
        st.error(f"‚ùå ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {model_path}\n{e}")

    try:
        with open(meta_path, "r", encoding="utf-8") as f:
            meta = json.load(f)
    except Exception:
        st.warning("‚ö†Ô∏è ‡∏≠‡πà‡∏≤‡∏ô model_meta.json ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‚Äî ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏ó‡∏ô.")
        meta = {
            "feature_cols": [
                "revenue_growth_ttm","gross_margin_ttm","operating_margin_ttm","net_margin_ttm",
                "roe_ttm","roa_ttm","debt_to_equity","ocf_to_cl","interest_coverage","asset_turnover_ttm"
            ],
            "exchange_suffix": ".BK",
            "forward_months": 6
        }
    return pipe, meta

pipe, meta = load_model_and_meta()
FEATURE_COLS: List[str] = meta.get("feature_cols", [])
SUFFIX: str = meta.get("exchange_suffix", ".BK")
FORWARD_MONTHS: int = meta.get("forward_months", 6)

# ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå (‡πÑ‡∏ó‡∏¢‡∏¢‡πà‡∏≠)
FEATURE_DESC = {
    "revenue_growth_ttm": "‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ (TTM, ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö TTM ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤)",
    "gross_margin_ttm": "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≥‡πÑ‡∏£‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô (TTM)",
    "operating_margin_ttm": "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≥‡πÑ‡∏£‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô (TTM)",
    "net_margin_ttm": "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥ (TTM)",
    "roe_ttm": "ROE (‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥ / ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ñ‡∏∑‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢)",
    "roa_ttm": "ROA (‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥ / ‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏£‡∏ß‡∏°‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢)",
    "debt_to_equity": "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô‡∏ï‡πà‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏ñ‡∏∑‡∏≠‡∏´‡∏∏‡πâ‡∏ô",
    "ocf_to_cl": "‡∏Å‡∏£‡∏∞‡πÅ‡∏™‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏î‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô (TTM) / ‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô",
    "interest_coverage": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ä‡∏≥‡∏£‡∏∞‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ (EBIT / |‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢|)",
    "asset_turnover_ttm": "‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÉ‡∏ä‡πâ‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå (‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ / ‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢)",
}

# =============================
# Helpers ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå
# =============================
def add_suffix_if_needed(symbol: str, suffix: str) -> str:
    return symbol if "." in symbol else (symbol + suffix)

def _lower_index(df):
    d2 = df.copy()
    d2.index = [str(i).strip().lower() for i in d2.index]
    return d2

def _pick_at(df, keys_like, col):
    if df is None or df.empty:
        return np.nan
    df = _lower_index(df)
    idx = df.index
    for k in keys_like:
        k = k.strip().lower()
        if k in idx:
            v = df.loc[k, col] if col in df.columns else np.nan
            if pd.notna(v): return float(v)
        matches = [i for i in idx if k in i]
        for m in matches:
            v = df.loc[m, col] if col in df.columns else np.nan
            if pd.notna(v): return float(v)
    return np.nan

def _ttm_sum_partial(df, keys_like, upto_cols, min_q=2, max_q=4):
    if df is None or df.empty:
        return np.nan
    df = _lower_index(df)
    for k in keys_like:
        k = k.strip().lower()
        rows = [k] if k in df.index else [i for i in df.index if k in i]
        for row in rows:
            vals = []
            for c in upto_cols[:max_q]:
                if c in df.columns:
                    v = df.loc[row, c]
                    if pd.notna(v):
                        vals.append(float(v))
            if len(vals) >= min_q:
                return float(np.sum(vals[:max_q]))
    return np.nan

def _avg_bs(df, keys_like, col_curr, col_prev):
    a = _pick_at(df, keys_like, col_curr)
    b = _pick_at(df, keys_like, col_prev) if col_prev is not None else np.nan
    if pd.isna(a) or pd.isna(b):
        return np.nan
    return (a + b) / 2.0

def safe_div(a, b):
    a = np.nan if pd.isna(a) else float(a)
    b = np.nan if pd.isna(b) else float(b)
    if pd.isna(a) or pd.isna(b) or b == 0:
        return np.nan
    return a / b

def safe_div_abs(a, b):
    a = np.nan if pd.isna(a) else float(a)
    b = np.nan if pd.isna(b) else float(b)
    if pd.isna(a) or pd.isna(b) or abs(b) < 1e-12:
        return np.nan
    return a / abs(b)

@st.cache_data(show_spinner=False)
def build_one_row_for_streamlit(ticker: str, suffix: str, feature_cols: List[str]):
    sym = add_suffix_if_needed(ticker, suffix)
    tk = yf.Ticker(sym)

    fin_q = tk.quarterly_financials
    bs_q  = tk.quarterly_balance_sheet
    cf_q  = tk.quarterly_cashflow
    if fin_q is None or fin_q.empty or bs_q is None or bs_q.empty or cf_q is None or cf_q.empty:
        return pd.DataFrame()

    cols = list(fin_q.columns)  # ‡πÉ‡∏´‡∏°‡πà‚Üí‡πÄ‡∏Å‡πà‡∏≤
    if len(cols) == 0:
        return pd.DataFrame()

    upto_cols = cols[:4]     # 4 ‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    col_curr = upto_cols[0]  # ‡∏á‡∏ö‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    col_prev = upto_cols[1] if len(upto_cols) > 1 else None

    # ----- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ TTM -----
    rev_ttm  = _ttm_sum_partial(fin_q, ["total revenue","revenue"], upto_cols)
    cogs_ttm = _ttm_sum_partial(fin_q, ["cost of revenue","cost of goods"], upto_cols)
    gp_ttm   = rev_ttm - cogs_ttm if pd.notna(rev_ttm) and pd.notna(cogs_ttm) else np.nan
    op_ttm   = _ttm_sum_partial(fin_q, ["operating income","ebit"], upto_cols)
    ni_ttm   = _ttm_sum_partial(fin_q, ["net income"], upto_cols)
    ebit_ttm = _ttm_sum_partial(fin_q, ["ebit","operating income"], upto_cols)
    int_ttm  = _ttm_sum_partial(fin_q, ["interest expense"], upto_cols)
    ocf_ttm  = _ttm_sum_partial(cf_q, ["operating cash flow","net cash provided by operating activities"], upto_cols)

    # ----- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì revenue_growth_ttm = (TTM_now - TTM_prev) / TTM_prev -----
    rev_ttm_prev = np.nan
    if len(cols) >= 5:
        prev_cols = cols[1:5]  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏õ 1 ‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™ (‡∏≠‡∏µ‡∏Å 4 ‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™‡∏ñ‡∏±‡∏î‡πÑ‡∏õ)
        rev_ttm_prev = _ttm_sum_partial(fin_q, ["total revenue","revenue"], prev_cols)
    rev_growth_ttm = safe_div(rev_ttm - rev_ttm_prev, rev_ttm_prev)

    # ----- ‡∏á‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ê‡∏≤‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (ROE/ROA/Asset turnover) -----
    total_assets_avg = _avg_bs(bs_q, ["total assets"], col_curr, col_prev) if col_prev is not None else np.nan
    sh_equity_avg    = _avg_bs(bs_q, ["total stockholder equity","total shareholders equity","total equity"],
                               col_curr, col_prev) if col_prev is not None else np.nan

    total_liab_curr  = _pick_at(bs_q, ["total liab","total liabilities"], col_curr)
    curr_liab_curr   = _pick_at(bs_q, ["total current liabilities","current liabilities"], col_curr)
    sh_equity_curr   = _pick_at(bs_q, ["total stockholder equity","total shareholders equity","total equity"], col_curr)

    row = {
        "ticker": ticker,
        "asof": pd.Timestamp(col_curr).to_pydatetime(),
        "revenue_growth_ttm": rev_growth_ttm,                 # << ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏£‡∏¥‡∏á
        "gross_margin_ttm": safe_div(gp_ttm, rev_ttm),
        "operating_margin_ttm": safe_div(op_ttm, rev_ttm),
        "net_margin_ttm": safe_div(ni_ttm, rev_ttm),
        "roe_ttm": safe_div(ni_ttm, sh_equity_avg),
        "roa_ttm": safe_div(ni_ttm, total_assets_avg),
        "debt_to_equity": safe_div(total_liab_curr, sh_equity_curr),
        "ocf_to_cl": safe_div(ocf_ttm, curr_liab_curr),
        "interest_coverage": safe_div_abs(ebit_ttm, int_ttm),
        "asset_turnover_ttm": safe_div(rev_ttm, total_assets_avg),
    }
    df = pd.DataFrame([row])
    for c in feature_cols:
        if c not in df.columns:
            df[c] = np.nan
    return df

# =============================
# UI
# =============================
st.title("üìà ‡∏™‡πÅ‡∏Å‡∏ô‡∏´‡∏∏‡πâ‡∏ô: ‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠ / ‡πÑ‡∏°‡πà‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠ (Fundamental ML)")
st.caption("‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡∏à‡∏≤‡∏Å Yahoo Finance ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå 10 ‡∏ï‡∏±‡∏ß ‡πÅ‡∏•‡πâ‡∏ß‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ß‡πà‡∏≤‡∏´‡∏∏‡πâ‡∏ô ‚Äò‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠‚Äô ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà")

with st.sidebar:
    st.header("‚öôÔ∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
    default_tickers = "PTT, AOT, KBANK, CPALL, ADVANC, SCB, BBL, KTB, DELTA, GULF"
    tickers_text = st.text_area("‡∏ä‡∏∑‡πà‡∏≠‡∏¢‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ ,)", value=default_tickers, height=100)
    suffix = st.text_input("‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ï‡∏•‡∏≤‡∏î (Yahoo)", value=SUFFIX, help="‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡πÉ‡∏ä‡πâ .BK ‡πÄ‡∏ä‡πà‡∏ô PTT.BK")
    threshold = st.slider("‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô (‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô ‚â• ‡πÄ‡∏Å‡∏ì‡∏ë‡πå)", 0.1, 0.9, 0.5, 0.01)
    run_btn = st.button("üîÆ ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå")

left, right = st.columns([2,1])

with left:
    st.subheader("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå")
    if pipe is None:
        st.info("‡πÇ‡∏õ‡∏£‡∏î‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå buy_model_pipeline.pkl ‡πÅ‡∏•‡∏∞ model_meta.json ‡πÑ‡∏ß‡πâ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÅ‡∏≠‡∏õ")
    elif run_btn:
        tickers = [t.strip() for t in tickers_text.split(",") if t.strip()]
        rows = []
        progress = st.progress(0)
        for i, tk in enumerate(tickers, start=1):
            rows.append(build_one_row_for_streamlit(tk, suffix, FEATURE_COLS))
            progress.progress(int(i/len(tickers)*100))
        rows = [r for r in rows if not r.empty]
        if len(rows) == 0:
            st.warning("‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ú‡∏¥‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏á‡∏ö‡πÉ‡∏ô Yahoo)")
        else:
            dfX = pd.concat(rows, ignore_index=True)
            X = dfX[FEATURE_COLS].astype(float)

            # ----- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì proba ‡∏û‡∏£‡πâ‡∏≠‡∏° normalize ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô 0..1 ‡πÄ‡∏™‡∏°‡∏≠ -----
            try:
                proba = pipe.predict_proba(X)[:, 1].astype(float)
            except Exception:
                _patch_monotonic_cst(pipe)
                try:
                    proba = pipe.predict_proba(X)[:, 1].astype(float)
                except Exception:
                    proba = pipe.predict(X).astype(float)

            proba = np.asarray(proba, dtype=float).reshape(-1)
            while np.nanmax(proba) > 1.0:
                proba = proba / 100.0
            proba = np.clip(proba, 0.0, 1.0)
            # -------------------------------------------------------

            out = dfX[["ticker","asof"]].copy()
            out["proba_buy"] = proba
            out["pred"] = (out["proba_buy"] >= threshold).astype(int)

            df_show = out.copy()
            df_show["‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠ (%)"] = (df_show["proba_buy"] * 100).round(1)
            df_show["‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"]   = np.where(df_show["pred"] == 1, "‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠ ‚úÖ", "‡πÑ‡∏°‡πà‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠ ‚ùå")
            df_show = df_show.rename(columns={"ticker": "‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå", "asof": "‡∏á‡∏ö ‡∏ì ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà"})[
                ["‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå","‡∏á‡∏ö ‡∏ì ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà","‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠ (%)","‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"]
            ].sort_values("‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠ (%)", ascending=False).reset_index(drop=True)

            st.dataframe(df_show, use_container_width=True, height=420)
            st.download_button(
                "üíæ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV",
                df_show.to_csv(index=False).encode("utf-8"),
                "predictions_streamlit_th.csv",
                "text/csv",
            )

with right:
    st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    st.markdown(
        f"**‡∏ô‡∏¥‡∏¢‡∏≤‡∏°‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö (Label):** ‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤ **{FORWARD_MONTHS} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô > 0%** ‚áí *‡∏ô‡πà‡∏≤‡∏ã‡∏∑‡πâ‡∏≠*  \n"
        f"**‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô:** proba ‚â• **{threshold if 'threshold' in locals() else 0.5:.2f}**"
    )
    st.markdown("**‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (10 ‡∏ï‡∏±‡∏ß):**")
    for key in FEATURE_COLS:
        th = FEATURE_DESC.get(key, key)
        st.markdown(f"- `{key}` ‚Äî {th}")

    st.markdown(
        f"**‡πÇ‡∏°‡πÄ‡∏î‡∏•:** `sklearn Pipeline` (SimpleImputer ‚Üí RandomForestClassifier)  \n"
        f"**‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏£‡∏±‡∏ô‡πÑ‡∏ó‡∏°‡πå:** scikit-learn `{sklearn.__version__}`  \n"
        f"**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ **‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô**"
    )

    st.markdown("---")
    st.subheader("‡∏î‡∏π‡∏Å‡∏£‡∏≤‡∏ü‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏£‡πá‡∏ß ‡πÜ")
    one = st.text_input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏∏‡πâ‡∏ô (1 ‡∏ï‡∏±‡∏ß)", value="PTT")
    period = st.selectbox("‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤", ["1 ‡∏õ‡∏µ","2 ‡∏õ‡∏µ","5 ‡∏õ‡∏µ","‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"], index=1)
    period_map = {"1 ‡∏õ‡∏µ":"1y","2 ‡∏õ‡∏µ":"2y","5 ‡∏õ‡∏µ":"5y","‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":"max"}
    if st.button("üìä ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü"):
        sym = add_suffix_if_needed(one.strip(), suffix)
        try:
            hist = yf.Ticker(sym).history(period=period_map[period])
            if len(hist) > 0:
                st.line_chart(hist["Close"], height=250)
            else:
                st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤")
        except Exception as e:
            st.error(str(e))

st.markdown("---")
st.caption("‡∏à‡∏±‡∏î‡∏ó‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏î‡πâ‡∏≤‡∏ô Data Science/ML")
